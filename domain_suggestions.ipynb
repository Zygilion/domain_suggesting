{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1 - Install requirements"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Change torch version if you are currently using some different one"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T09:51:59.569359Z",
     "start_time": "2025-09-02T09:51:40.656480Z"
    }
   },
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check torch==2.6.0 transformers accelerate evaluate rouge_score loralib peft tqdm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.11/site-packages (24.3.1)\r\n",
      "Collecting pip\r\n",
      "  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Using cached pip-25.2-py3-none-any.whl (1.8 MB)\r\n",
      "Installing collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 24.3.1\r\n",
      "    Uninstalling pip-24.3.1:\r\n",
      "      Successfully uninstalled pip-24.3.1\r\n",
      "Successfully installed pip-25.2\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch==2.6.0 in ./.venv/lib/python3.11/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.11/site-packages (4.56.0)\r\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.11/site-packages (1.10.1)\r\n",
      "Collecting evaluate\r\n",
      "  Using cached evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\r\n",
      "Collecting rouge_score\r\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\r\n",
      "Collecting loralib\r\n",
      "  Using cached loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: peft in ./.venv/lib/python3.11/site-packages (0.17.1)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (3.19.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (2025.7.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.11/site-packages (from transformers) (0.34.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from transformers) (2.3.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers) (2025.9.1)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers) (2.32.5)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.11/site-packages (from transformers) (0.22.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers) (0.6.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\r\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from accelerate) (7.0.0)\r\n",
      "Collecting datasets>=2.0.0 (from evaluate)\r\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting dill (from evaluate)\r\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting pandas (from evaluate)\r\n",
      "  Using cached pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\r\n",
      "Collecting xxhash (from evaluate)\r\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from evaluate)\r\n",
      "  Using cached multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\r\n",
      "Collecting absl-py (from rouge_score)\r\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting nltk (from rouge_score)\r\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: six>=1.14.0 in ./.venv/lib/python3.11/site-packages (from rouge_score) (1.17.0)\r\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\r\n",
      "  Using cached pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting dill (from evaluate)\r\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting multiprocess (from evaluate)\r\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec (from torch==2.6.0)\r\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Using cached aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Using cached frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Using cached multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Using cached propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Using cached yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch==2.6.0) (3.0.2)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk->rouge_score) (8.2.1)\r\n",
      "Collecting joblib (from nltk->rouge_score)\r\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Collecting pytz>=2020.1 (from pandas->evaluate)\r\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas->evaluate)\r\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Using cached evaluate-0.4.5-py3-none-any.whl (84 kB)\r\n",
      "Using cached loralib-0.1.2-py3-none-any.whl (10 kB)\r\n",
      "Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\r\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\r\n",
      "Using cached aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "Using cached multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\r\n",
      "Using cached yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\r\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\n",
      "Using cached frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\r\n",
      "Using cached propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\r\n",
      "Using cached pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\r\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\r\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\r\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\r\n",
      "Using cached pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\r\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, loralib, joblib, fsspec, frozenlist, dill, aiohappyeyeballs, absl-py, yarl, pandas, nltk, multiprocess, aiosignal, rouge_score, aiohttp, datasets, evaluate\r\n",
      "\u001B[2K  Attempting uninstall: fsspec\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 7/22\u001B[0m [joblib]]\r\n",
      "\u001B[2K    Found existing installation: fsspec 2025.7.0━━━━━━━━━━━━━━\u001B[0m \u001B[32m 7/22\u001B[0m [joblib]\r\n",
      "\u001B[2K    Uninstalling fsspec-2025.7.0:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 7/22\u001B[0m [joblib]\r\n",
      "\u001B[2K      Successfully uninstalled fsspec-2025.7.0━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m 7/22\u001B[0m [joblib]\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m22/22\u001B[0m [evaluate]/22\u001B[0m [evaluate]]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed absl-py-2.3.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 datasets-4.0.0 dill-0.3.8 evaluate-0.4.5 frozenlist-1.7.0 fsspec-2025.3.0 joblib-1.5.2 loralib-0.1.2 multidict-6.6.4 multiprocess-0.70.16 nltk-3.9.1 pandas-2.3.2 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 rouge_score-0.1.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": "Import necessary packages"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T09:56:17.346873Z",
     "start_time": "2025-09-02T09:56:13.820427Z"
    }
   },
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, \\\n",
    "    DataCollatorForLanguageModeling, GenerationConfig"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zygimantas/PycharmProjects/domain_suggesting/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Generating domain name suggestions using Prompt Engineering\n",
    "\n",
    "For this task I have chosen Qwen3-0.6B because it is small and would fully fit into my machines VRAM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iAYlS40Z3l-v",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-02T09:56:43.409399Z",
     "start_time": "2025-09-02T09:56:41.468876Z"
    }
   },
   "source": [
    "model_name = 'Qwen/Qwen3-0.6B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "First I want to test how this model would generate domain names without any prompt engineering"
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-30T09:47:40.735867Z",
     "start_time": "2025-08-30T09:47:35.536350Z"
    }
   },
   "source": [
    "prompt = \"Give me domain name suggestion based on this business description - My business is a specialized online marketplace dedicated to showcasing and selling small Japanese board games\"\n",
    "messages = [\n",
    "    {'role': 'user', 'content': prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some domain name suggestions based on your business description:\n",
      "\n",
      "1. **JagameMarket.com**  \n",
      "2. **JagameShop.com**  \n",
      "3. **JagameOnline.com**  \n",
      "4. **JagameLabs.com**  \n",
      "5. **JagameTales.com**  \n",
      "6. **JagameGames.com**  \n",
      "7. **JagameGaming.com**  \n",
      "8. **JagameWorld.com**  \n",
      "9. **JagameWorldOnline.com**  \n",
      "10. **JagameJunk.com**  \n",
      "\n",
      "These names are all related to Japanese board games and could work well for your online marketplace. Let me know if you'd like more options!\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"Jagame\" is repeated for every given domain name, which show no creativity. It could be improved by providing only the domain names, without any explanation and in a more structured way, also more creative."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 - Zero Shot Inference\n",
    "I will test how the model would output domain names with clear instructions what I want to see in the models output - 10 domains in a list."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-30T09:50:18.213853Z",
     "start_time": "2025-08-30T09:50:15.762706Z"
    }
   },
   "source": [
    "business_description = \"My business is a specialized online marketplace dedicated to showcasing and selling small Japanese board games\"\n",
    "prompt = \"\"\"You are a domain name generator. Suggest 10 creative, brandable, and easy-to-remember domain names based on the business description. The names should be:\n",
    "- Short, catchy, and easy to spell\n",
    "- Available in common domain extensions like .com, .store, or .shop\n",
    "- Avoid using hyphens or numbers unless essential\n",
    "\n",
    "Respond ONLY with a list in the following structure:\n",
    "1. domain_name.com\n",
    "2. domain_name.com\n",
    "...\n",
    "\n",
    "Do not include any additional text outside of the list.\n",
    "Here is the business description:\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {'role': 'user', 'content': prompt + business_description}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. boardgamehub.com  \n",
      "2. gameshow.com  \n",
      "3. japanboardgames.com  \n",
      "4. jpopgames.com  \n",
      "5. gamezone.com  \n",
      "6. jgamestore.com  \n",
      "7. japangames.com  \n",
      "8. gamestore.com  \n",
      "9. boardgame.com  \n",
      "10. japangames.com\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This is better because of the output structure, which could be later used for easy parsing. However the names could be more creative and also with different TLDs, because most likely these domains would be already taken."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 - One Shot Inference\n",
    "I will add one example to the models input to see if it helps with providing different TLDs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-30T10:24:21.328326Z",
     "start_time": "2025-08-30T10:24:18.793789Z"
    }
   },
   "source": [
    "business_description_example = \"\"\"This business provides AI-powered retail crime prevention solutions for self-checkout systems\n",
    "1. scanshield.ai\n",
    "2. checkoutguard.eu\n",
    "3. retailsentinel.com\n",
    "4. shopsecure.ai\n",
    "5. fraudblocker.tech\n",
    "6. safescantech.top\n",
    "7. retailwatchpro.store\n",
    "8. smartcartsecurity.info\n",
    "9. visioncheckout.org\n",
    "10. guardpointai.net\n",
    "\n",
    "Here is the business description:\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {'role': 'user', 'content': prompt + business_description_example + business_description}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. japanboard.com  \n",
      "2. gamehaven.store  \n",
      "3. boardgamehub.net  \n",
      "4. gamesworld.io  \n",
      "5. japangames.com  \n",
      "6. boardgamesstore.net  \n",
      "7. japangamesinfo.com  \n",
      "8. boardgamearena.org  \n",
      "9. gamescape.io  \n",
      "10. japangamesstore.com\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The output is in the same format as well as in zero-shot inference, but the names generated have different TLDs, which is what I wanted, however most of the names are generic, not creative, which would most likely mean that they would be taken."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 - Few Shot Inference\n",
    "I will add even more examples to the models input to see if it helps with providing even more different TLDs and more creative names."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T10:24:31.007766Z",
     "start_time": "2025-08-30T10:24:28.187395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "business_description_example_2 = \"\"\"Digital marketing agency focused on helping small businesses grow online\n",
    "1. growthdigital.eu\n",
    "2. digitalreach.io\n",
    "3. smallbizboom.co\n",
    "4. marketgrowpro.com\n",
    "5. digitalboostlab.top\n",
    "6. onlinebizhelp.store\n",
    "7. growthmarketing.info\n",
    "8. digitalscalehub.zone\n",
    "9. bizgrowthpartners.link\n",
    "10. marketinglaunchpad.biz\n",
    "\n",
    "\n",
    "Here is the business description:\n",
    "\"\"\"\n",
    "business_description_example_3 = \"\"\"Fitness studio offering yoga, pilates, and meditation classes\n",
    "1. zenfitstudio.org\n",
    "2. mindfulmovement.co\n",
    "3. yogabliss.net\n",
    "4. pilatespure.com\n",
    "5. serenityworkout.top\n",
    "6. balancestudiohub.link\n",
    "7. flowfitnesscenter.biz\n",
    "8. tranquilbody.info\n",
    "9. holisticfitlab.zone\n",
    "10. peacefulpilates.store\n",
    "\n",
    "\n",
    "Here is the business description:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {'role': 'user',\n",
    "     'content': prompt + business_description_example + business_description_example_2 + business_description_example_3 + business_description}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. boardgamehub.com  \n",
      "2. gamestore.co  \n",
      "3. japan_games.info  \n",
      "4. johokagame.com  \n",
      "5. boardgameshop.com  \n",
      "6. jisagame.net  \n",
      "7. boardgamesupply.com  \n",
      "8. japanboardgames.store  \n",
      "9. japan-games.net  \n",
      "10. boardgamesmall.com\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By providing even more examples it now generates domains with different TLDs and a relevant domain name to the business description and a bit more creative names, however creativeness could still be improved, because now it is mostly generic words / names."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.4 - Parameter tuning\n",
    "I will now test parameter tuning such as `temperature` changing and thinking mode\n",
    "\n",
    "The default temperature settings for this model is `temperature=0.6`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-30T10:19:01.350855Z",
     "start_time": "2025-08-30T10:18:58.295428Z"
    }
   },
   "source": [
    "generation_config = GenerationConfig(do_sample=True, temperature=0.1)\n",
    "messages = [\n",
    "    {'role': 'user',\n",
    "     'content': prompt + business_description_example + business_description_example_2 + business_description_example_3 + business_description}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    generation_config=generation_config,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. boardgamestore.com  \n",
      "2. jumigamed.com  \n",
      "3. gamehub.net  \n",
      "4. jumigam.com  \n",
      "5. boardgameshop.com  \n",
      "6. jumigamstore.com  \n",
      "7. gamezone.com  \n",
      "8. boardgames.net  \n",
      "9. jumigamstore.org  \n",
      "10. boardgamesmall.com\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "By including `do_sample=True` and `temperature=0.1` I now get non creative domain names with most of them being almost repeated, such as \"jumigam\" and \"boardgames\" and most of them are with `.com` extension"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T10:25:59.913757Z",
     "start_time": "2025-08-30T10:25:56.676680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generation_config = GenerationConfig(do_sample=True, temperature=0.9)\n",
    "messages = [\n",
    "    {'role': 'user',\n",
    "     'content': prompt + business_description_example + business_description_example_2 + business_description_example_3 + business_description}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    generation_config=generation_config,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. gameshop.com  \n",
      "2. boardgames.pro  \n",
      "3. jokobigame.top  \n",
      "4. nihongo_boardgames.org  \n",
      "5. jokobigames.com  \n",
      "6. boardgamestore.io  \n",
      "7. jokobigames.store  \n",
      "8. nihongo-boardgames.com  \n",
      "9. boardgames.com  \n",
      "10. gameshop.net\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By including `do_sample=True` and `temperature=0.9` I now get more creative outputs, however some of them are irrelevant to the business description, it just integrates some random Japanese words to the domain name. This is too random."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T10:27:19.405143Z",
     "start_time": "2025-08-30T10:27:16.425392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generation_config = GenerationConfig(do_sample=True, temperature=0.7, top_p=0.8, top_k=20, min_p=0)\n",
    "start_time = time.time()\n",
    "messages = [\n",
    "    {'role': 'user',\n",
    "     'content': prompt + business_description_example + business_description_example_2 + business_description_example_3 + business_description}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    generation_config=generation_config,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)\n",
    "print('Time taken:', time.time() - start_time)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. boardgamez.com  \n",
      "2. gameguru.store  \n",
      "3. jokoboard.io  \n",
      "4. jumiboard.top  \n",
      "5. boardgameshop.org  \n",
      "6. boardgames.net  \n",
      "7. gamestore24.com  \n",
      "8. jokoboard.info  \n",
      "9. boardgamehub.com  \n",
      "10. boardgamezone.org\n",
      "Time taken: 2.9761745929718018\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I have now used the suggested parameters from HuggingFace page for this model without using Thinking mode.\n",
    "\n",
    "Domain names are mostly relevant to the description, but the names are being repeated also, such as \"boardgame\" and some kind of random words are being used, such as \"joko\", \"jumi\" which do not help with brandability."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T10:29:28.882697Z",
     "start_time": "2025-08-30T10:29:04.634082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generation_config = GenerationConfig(do_sample=True, temperature=0.6, top_p=0.95, top_k=20, min_p=0)\n",
    "messages = [\n",
    "    {'role': 'user',\n",
    "     'content': prompt + business_description_example + business_description_example_2 + business_description_example_3 + business_description}\n",
    "]\n",
    "start_time = time.time()\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    generation_config=generation_config,\n",
    "    max_new_tokens=1000\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip('\\n')\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print('thinking content:', thinking_content)\n",
    "print('content:', content)\n",
    "print('Time taken:', time.time() - start_time)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's see. The user wants me to generate 10 domain names based on a business description. The business is a specialized online marketplace for small Japanese board games. The domain names need to be short, catchy, easy to spell, available in common extensions like .com, .store, .shop, and avoid hyphens or numbers unless necessary.\n",
      "\n",
      "First, I need to make sure each domain name is unique and fits the theme. The user provided some examples, so I should check if they already have those. The first business description is about AI for retail, so the next one is about digital marketing, then fitness studio, and finally Japanese board games.\n",
      "\n",
      "Starting with the Japanese board games. Words like \"zen,\" \"yog\" (yoga), \"mindful,\" \"serenity,\" \"holy,\" \"peaceful,\" \"tranquil,\" \"holistic,\" \"peaceful.\" Maybe combine these with common extensions. For example, \"zenboardstore.org\" uses \"zen\" and \"store,\" which is a common extension. \"mindfulgames.com\" uses \"mindful\" and \"games.\" \"yogaboard.info\" uses \"yog\" and \"board.\" \n",
      "\n",
      "I need to avoid hyphens and numbers. Let's check each name. The first example given in the list is \"scanshield.ai,\" which is a bit long. The user's instruction says to avoid hyphens unless needed, so hyphens shouldn't be used. So, \"scanshield\" is okay as is. \n",
      "\n",
      "Wait, the user's examples have .com, .store, .shop. So I should use those. Let me think of more variations. Maybe \"yogaboardstore.com\" instead of \"yogaboard.info\" if the extension is .com. Also, \"mindfulgames.com\" is a good one. \"serenityworkout.top\" is another. \n",
      "\n",
      "I need to make sure each domain is unique and not overlapping with the previous ones. Let me list them out again. \n",
      "\n",
      "1. zenboardstore.com\n",
      "2. mindfulgames.com\n",
      "3. yogaboard.info\n",
      "4. serenityworkout.top\n",
      "5. holisticfitness.info\n",
      "6. peacefulpilatesstore.com\n",
      "7. tranquilitygames.com\n",
      "8. mindfulclassroom.com\n",
      "9. zenfitnessstudio.org\n",
      "10. yogaholistic.com\n",
      "\n",
      "Wait, maybe \"yogaholistic.com\" is better. Let me check if \"yogaholistic.com\" uses hyphens. No, it's just \"yogaholistic.\" That's good. Also, \"mindfulclassroom.com\" uses \"classroom,\" which is a common extension. \n",
      "\n",
      "Yes, these should meet all the requirements. Each name is short, catchy, uses .com, .store, .shop extensions, no hyphens, and avoids numbers. They all seem to fit the theme of a Japanese board game marketplace.\n",
      "</think>\n",
      "content: 1. zenboardstore.com  \n",
      "2. mindfulgames.com  \n",
      "3. yogaboard.info  \n",
      "4. serenityworkout.top  \n",
      "5. holisticfitness.info  \n",
      "6. peacefulpilatesstore.com  \n",
      "7. tranquilitygames.com  \n",
      "8. mindfulclassroom.com  \n",
      "9. zenfitnessstudio.org  \n",
      "10. yogaholistic.com\n",
      "Time taken: 24.2429039478302\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I have used Thinking mode now with suggested parameters from the HuggingFace repo for this model - `temperature=0.6`, `top_p=0.95`, `top_k=20`, `min_p=0`.\n",
    "\n",
    "These results are not good, because it takes too much inspiration from the few shot examples provided, also it takes 8 times longer to complete the inference, so I would say that Thinking mode should not be used for this task, especially because it provides much worse results I think because of too much context being provided to the model and because it is quite small - 0.6B it kind of starts to hallucinate."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In conclusion from Prompt engineering the best results have been by using few-shot inference and default parameters for the Qwen3-0.6B model without the thinking mode enabled, but the results could be more creative and not as random."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3 - Fine tuning open source LLM model for domain name suggesting\n",
    "\n",
    "I will fine tune the Qwen3-0.6B model by using LoRA and gathering my own dataset which will have this format - (business description, relevant domain name)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1 - Creating dataset\n",
    "I will create the dataset by using OpenAIs GPT 5 model by prompting it manually and processing it into usable format with python scripting.\n",
    "\n",
    "Prompt used:\n",
    "\n",
    "Create a dataset which I would be able to use to train LLM. Dataset should have these pairs - (business description, relevant domain name). An example of pair - (Fitness studio offering yoga, pilates, and meditation classes, 1. zenfitstudio.org\n",
    "2. mindfulmovement.co\n",
    "3. yogabliss.net\n",
    "4. pilatespure.com\n",
    "5. serenityworkout.top\n",
    "6. balancestudiohub.link\n",
    "7. flowfitnesscenter.biz\n",
    "8. tranquilbody.info\n",
    "9. holisticfitlab.zone\n",
    "10. peacefulpilates.store)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T08:44:06.003160Z",
     "start_time": "2025-08-31T08:44:05.991145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_pairs_file(file_path: str) -> List[Tuple[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    Parse the pairs file and extract business description with all domain suggestions.\n",
    "    Each business description gets paired with all of its domain suggestions as a list.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Split by business entries (separated by ---)\n",
    "    entries = content.split('---')\n",
    "\n",
    "    for entry in entries:\n",
    "        if not entry.strip():\n",
    "            continue\n",
    "\n",
    "        # Extract business description\n",
    "        desc_match = re.search(r'\\*\\*Business Description:\\*\\* (.+?)(?=\\n\\n|\\n\\*\\*|$)', entry, re.DOTALL)\n",
    "        if not desc_match:\n",
    "            continue\n",
    "\n",
    "        business_desc = desc_match.group(1).strip()\n",
    "\n",
    "        # Extract domain suggestions\n",
    "        domain_section = re.search(r'\\*\\*Domain Suggestions:\\*\\*.*?(?=\\n\\n|$)', entry, re.DOTALL)\n",
    "        if not domain_section:\n",
    "            continue\n",
    "\n",
    "        # Extract individual domain names\n",
    "        domain_lines = domain_section.group(0).split('\\n')[1:]  # Skip the header\n",
    "        domains = []\n",
    "        for line in domain_lines:\n",
    "            if line.strip() and re.match(r'\\d+\\.\\s+', line):\n",
    "                domain = re.search(r'\\d+\\.\\s+(.+)', line).group(1).strip()\n",
    "                if domain:\n",
    "                    domains.append(domain)\n",
    "\n",
    "        if domains:\n",
    "            pairs.append((business_desc, domains))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def create_training_format(pairs: List[Tuple[str, List[str]]]) -> List[dict]:\n",
    "    training_data = []\n",
    "\n",
    "    for business_desc, domains in pairs:\n",
    "        # Create a prompt-completion pair with multiple domain suggestions\n",
    "        prompt = f'Here is the business description:\\n{business_desc}'\n",
    "\n",
    "        # Format completion with numbered domain suggestions\n",
    "        completion_lines = []\n",
    "        for i, domain in enumerate(domains, 1):\n",
    "            completion_lines.append(f'{i}. {domain}')\n",
    "\n",
    "        completion = '\\n'.join(completion_lines)\n",
    "\n",
    "        training_data.append({\n",
    "            'prompt': prompt,\n",
    "            'completion': completion\n",
    "        })\n",
    "\n",
    "    return training_data\n",
    "\n",
    "\n",
    "def split_data(pairs: List[Tuple[str, List[str]]], train_ratio: float = 0.8, random_seed: int = 42) -> Tuple[\n",
    "    List[Tuple[str, List[str]]], List[Tuple[str, List[str]]]]:\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "        pairs: List of (business_description, domain_suggestions) tuples\n",
    "        train_ratio: Ratio of data to use for training (default: 0.8)\n",
    "        random_seed: Random seed for reproducibility (default: 42)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (training_pairs, testing_pairs)\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # Shuffle the pairs\n",
    "    shuffled_pairs = pairs.copy()\n",
    "    random.shuffle(shuffled_pairs)\n",
    "\n",
    "    # Calculate split point\n",
    "    split_index = int(len(shuffled_pairs) * train_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    training_pairs = shuffled_pairs[:split_index]\n",
    "    testing_pairs = shuffled_pairs[split_index:]\n",
    "\n",
    "    return training_pairs, testing_pairs\n",
    "\n",
    "\n",
    "def save_training_data(training_data: List[dict], output_path: str):\n",
    "    \"\"\"Save training data to JSON file.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# Parse the pairs file\n",
    "pairs = parse_pairs_file('data/pairs')\n",
    "print(f\"Found {len(pairs)} business descriptions with domain suggestions\")\n",
    "\n",
    "# Split into training and testing sets\n",
    "training_pairs, testing_pairs = split_data(pairs, train_ratio=0.8, random_seed=42)\n",
    "print(f\"Training set: {len(training_pairs)} examples\")\n",
    "print(f\"Testing set: {len(testing_pairs)} examples\")\n",
    "\n",
    "# Create training data\n",
    "training_data = create_training_format(training_pairs)\n",
    "testing_data = create_training_format(testing_pairs)\n",
    "\n",
    "# Save both datasets\n",
    "save_training_data(training_data, 'data/training_dataset.json')\n",
    "save_training_data(testing_data, 'data/testing_dataset.json')\n",
    "\n",
    "print('\\nExample training pairs:')\n",
    "for i, example in enumerate(training_data[:2]):\n",
    "    print(f'\\nExample {i + 1}:')\n",
    "    print(f'Prompt: {example[\"prompt\"]}')\n",
    "    print(f'Completion: {example[\"completion\"]}')\n",
    "    print('-' * 50)\n",
    "\n",
    "print('\\nExample testing pairs:')\n",
    "for i, example in enumerate(testing_data[:2]):\n",
    "    print(f'\\nExample {i + 1}:')\n",
    "    print(f'Prompt: {example[\"prompt\"]}')\n",
    "    print(f'Completion: {example[\"completion\"]}')\n",
    "    print('-' * 50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 business descriptions with domain suggestions\n",
      "Training set: 20 examples\n",
      "Testing set: 5 examples\n",
      "\n",
      "Example training pairs:\n",
      "\n",
      "Example 1:\n",
      "Prompt: Here is the business description:\n",
      "Food truck serving gourmet burgers made with locally sourced ingredients\n",
      "Completion: 1. gourmetburgertruck.com\n",
      "2. localingredientsburgers.food\n",
      "3. foodtruckgourmet.net\n",
      "4. artisanburgermobile.org\n",
      "5. farmtotablburgers.co\n",
      "6. mobilegourmetburgers.biz\n",
      "7. localburgertruck.info\n",
      "8. gourmetstreetburgers.truck\n",
      "9. farmfreshburgertruck.mobile\n",
      "10. artisanburgerco.food\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Prompt: Here is the business description:\n",
      "Yoga instructor offering private classes and corporate wellness programs\n",
      "Completion: 1. privateyogainstructor.com\n",
      "2. corporatewellnessyoga.org\n",
      "3. personalyogateacher.net\n",
      "4. workplacewellnessyoga.co\n",
      "5. mindfulnessinstructor.biz\n",
      "6. yogaforcompanies.info\n",
      "7. privateyogasessions.pro\n",
      "8. corporateyogateacher.wellness\n",
      "9. customyogaprograms.services\n",
      "10. wellnessyogapro.consulting\n",
      "--------------------------------------------------\n",
      "\n",
      "Example testing pairs:\n",
      "\n",
      "Example 1:\n",
      "Prompt: Here is the business description:\n",
      "Children's daycare center with educational programs for ages 2-5\n",
      "Completion: 1. littlelearnersdaycare.com\n",
      "2. brightstartchildcare.org\n",
      "3. kidslearningcenter.net\n",
      "4. earlyeducationhub.co\n",
      "5. playfullearningdaycare.biz\n",
      "6. creativekidscare.info\n",
      "7. nurturingmindschildcare.care\n",
      "8. happychildrenscenter.org\n",
      "9. developmentaldaycare.edu\n",
      "10. kidsfirstlearning.center\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Prompt: Here is the business description:\n",
      "Plumbing service company offering residential and commercial repairs\n",
      "Completion: 1. reliableplumbingpros.com\n",
      "2. quickfixplumbing.service\n",
      "3. masterplumbersolutions.net\n",
      "4. emergencyplumbingteam.org\n",
      "5. professionalplumberco.biz\n",
      "6. plumbingexpertsgroup.pro\n",
      "7. fastplumbingrepairs.info\n",
      "8. qualityplumbingservice.co\n",
      "9. trustedplumbersteam.services\n",
      "10. plumbingsolutionspro.repair\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Output of GPT 5 model is stored in `data/pairs` file. It got processed using python into two separate JSON files for training and testing fine tuned model."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T08:45:17.564326Z",
     "start_time": "2025-08-31T08:45:17.558889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_training_data(tokenizer, file_path: str):\n",
    "    \"\"\"Load the training dataset from JSON file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    texts = []\n",
    "    for item in data:\n",
    "        # Create chat messages\n",
    "        messages = [\n",
    "            {'role': 'user', 'content': item['prompt']},\n",
    "            {'role': 'assistant', 'content': item['completion']}\n",
    "        ]\n",
    "\n",
    "        # Apply chat template to create the training text\n",
    "        # This will format it exactly like the model expects during inference\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "def tokenize_function(examples, tokenizer, max_length=512):\n",
    "    tokenized = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    tokenized['labels'] = tokenized['input_ids'].clone()\n",
    "\n",
    "    return tokenized"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T08:46:40.753394Z",
     "start_time": "2025-08-31T08:45:20.409602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'Qwen/Qwen3-0.6B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "print('Loading training dataset...')\n",
    "training_texts = load_training_data(tokenizer, 'data/training_dataset.json')\n",
    "\n",
    "dataset = Dataset.from_dict({'text': training_texts})\n",
    "print(f'Dataset size: {len(dataset)} examples')\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    lambda x: tokenize_function(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=dataset.column_names\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "output_dir = 'fine-tune-model'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=5,\n",
    "    save_steps=50,\n",
    "    save_total_limit=3,\n",
    "    warmup_steps=50,\n",
    "    lr_scheduler_type='cosine',\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None,\n",
    "    load_best_model_at_end=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print('Starting training...')\n",
    "trainer.train()\n",
    "\n",
    "print(f'Saving model to {output_dir}')\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset...\n",
      "Dataset size: 20 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20/20 [00:00<00:00, 1462.68 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,092,544 || all params: 606,142,464 || trainable%: 1.6650\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.812600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to fine-tune-model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fine-tune-model/tokenizer_config.json',\n",
       " 'fine-tune-model/special_tokens_map.json',\n",
       " 'fine-tune-model/chat_template.jinja',\n",
       " 'fine-tune-model/vocab.json',\n",
       " 'fine-tune-model/merges.txt',\n",
       " 'fine-tune-model/added_tokens.json',\n",
       " 'fine-tune-model/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you get Out of memory error try using `fp16=True` in `Training arguments`. By using given `Training arguments` training used ~4,6 GB of VRAM and on my machine took about 2 minutes."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T09:18:46.799366Z",
     "start_time": "2025-08-31T09:18:44.337647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'Qwen/Qwen3-0.6B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "fine_tuned_model = PeftModel.from_pretrained(base_model,\n",
    "                                             'fine-tune-model/',\n",
    "                                             torch_dtype='auto',\n",
    "                                             is_trainable=False)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T09:18:53.677872Z",
     "start_time": "2025-08-31T09:18:48.639794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = 'Here is the business description:\\nSpecialized online marketplace dedicated to showcasing and selling small Japanese board games'\n",
    "messages = [\n",
    "    {'role': 'user', 'content': prompt}\n",
    "]\n",
    "\n",
    "start_time = time.time()\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False  # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors='pt').to(fine_tuned_model.device)\n",
    "\n",
    "generation_config = GenerationConfig(do_sample=True, temperature=0.7, top_p=0.8, top_k=20, min_p=0)\n",
    "# conduct text completion\n",
    "generated_ids = fine_tuned_model.generate(\n",
    "    **model_inputs,\n",
    "    generation_config=generation_config,\n",
    "    max_new_tokens=500\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "print(content)\n",
    "print('Time taken:', time.time() - start_time)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. boardgamehub.jp\n",
      "2. gamesandgarden.net\n",
      "3. japanesegamedev.co\n",
      "4. boardgamepro.info\n",
      "5. onlinegamedev.org\n",
      "6. boardgameclub.biz\n",
      "7. gamegamedesign.jp\n",
      "8. onlinegamedesign.co\n",
      "9. boardgamearena.info\n",
      "10. gamesandgamedev.biz\n",
      "Time taken: 5.0345635414123535\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With fine tuned model I now get relevant to the business description domain names and a variety of extensions, with a simple prompt. Names could also be more creative, but by comparing them to few-shot results I would say these are more creative."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T09:20:36.090742Z",
     "start_time": "2025-08-31T09:19:41.555056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "\n",
    "def generate_response(model, prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate response from a model given a prompt.\n",
    "\n",
    "    Args:\n",
    "        model: The model to generate from\n",
    "        prompt: Input prompt\n",
    "\n",
    "    Returns:\n",
    "        Generated response\n",
    "    \"\"\"\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors='pt').to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            generation_config=generation_config,\n",
    "            max_new_tokens=500\n",
    "        )\n",
    "\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "    content = tokenizer.decode(output_ids, skip_special_tokens=True).strip('\\n')\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def calculate_rouge_scores(reference: str, prediction: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores between reference and prediction.\n",
    "\n",
    "    Args:\n",
    "        reference: Reference text\n",
    "        prediction: Predicted text\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with ROUGE scores\n",
    "    \"\"\"\n",
    "    scores = rouge_scorer.score(reference, prediction)\n",
    "\n",
    "    return {\n",
    "        'rouge1': scores['rouge1'].fmeasure,\n",
    "        'rouge2': scores['rouge2'].fmeasure,\n",
    "        'rougeL': scores['rougeL'].fmeasure\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_models(dataset_path: str, max_samples: int = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate both models on the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_path: Path to the JSON dataset\n",
    "        max_samples: Maximum number of samples to evaluate (None for all)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with evaluation results\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    print(f\"Loading dataset from {dataset_path}...\")\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    if max_samples:\n",
    "        dataset = dataset[:max_samples]\n",
    "\n",
    "    print(f\"Evaluating on {len(dataset)} samples...\")\n",
    "\n",
    "    base_scores = []\n",
    "    fine_tuned_scores = []\n",
    "    base_times = []\n",
    "    fine_tuned_times = []\n",
    "\n",
    "    for i, sample in enumerate(tqdm(dataset, desc=\"Evaluating\")):\n",
    "        prompt = sample['prompt']\n",
    "        reference = sample['completion']\n",
    "\n",
    "        # Generate with base model\n",
    "        start_time = time.time()\n",
    "        base_prediction = generate_response(base_model, prompt)\n",
    "        base_time = time.time() - start_time\n",
    "        base_times.append(base_time)\n",
    "\n",
    "        # Generate with fine-tuned model\n",
    "        start_time = time.time()\n",
    "        fine_tuned_prediction = generate_response(fine_tuned_model, prompt)\n",
    "        fine_tuned_time = time.time() - start_time\n",
    "        fine_tuned_times.append(fine_tuned_time)\n",
    "\n",
    "        # Calculate ROUGE scores\n",
    "        base_rouge = calculate_rouge_scores(reference, base_prediction)\n",
    "        fine_tuned_rouge = calculate_rouge_scores(reference, fine_tuned_prediction)\n",
    "\n",
    "        base_scores.append(base_rouge)\n",
    "        fine_tuned_scores.append(fine_tuned_rouge)\n",
    "\n",
    "        # Print sample comparison every 10 samples\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"\\nSample {i + 1}:\")\n",
    "            print(f\"Prompt: {prompt[:100]}...\")\n",
    "            print(f\"Reference: {reference[:100]}...\")\n",
    "            print(f\"Base: {base_prediction[:100]}...\")\n",
    "            print(f\"Fine-tuned: {fine_tuned_prediction[:100]}...\")\n",
    "            print(f\"Base ROUGE: {base_rouge}\")\n",
    "            print(f\"Fine-tuned ROUGE: {fine_tuned_rouge}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_base_scores = {\n",
    "        'rouge1': np.mean([s['rouge1'] for s in base_scores]),\n",
    "        'rouge2': np.mean([s['rouge2'] for s in base_scores]),\n",
    "        'rougeL': np.mean([s['rougeL'] for s in base_scores])\n",
    "    }\n",
    "\n",
    "    avg_fine_tuned_scores = {\n",
    "        'rouge1': np.mean([s['rouge1'] for s in fine_tuned_scores]),\n",
    "        'rouge2': np.mean([s['rouge2'] for s in fine_tuned_scores]),\n",
    "        'rougeL': np.mean([s['rougeL'] for s in fine_tuned_scores])\n",
    "    }\n",
    "\n",
    "    # Calculate average times\n",
    "    avg_base_time = np.mean(base_times)\n",
    "    avg_fine_tuned_time = np.mean(fine_tuned_times)\n",
    "\n",
    "    results = {\n",
    "        'base_model': {\n",
    "            'scores': avg_base_scores,\n",
    "            'avg_time': avg_base_time,\n",
    "            'individual_scores': base_scores\n",
    "        },\n",
    "        'fine_tuned_model': {\n",
    "            'scores': avg_fine_tuned_scores,\n",
    "            'avg_time': avg_fine_tuned_time,\n",
    "            'individual_scores': fine_tuned_scores\n",
    "        },\n",
    "        'improvement': {\n",
    "            'rouge1': avg_fine_tuned_scores['rouge1'] - avg_base_scores['rouge1'],\n",
    "            'rouge2': avg_fine_tuned_scores['rouge2'] - avg_base_scores['rouge2'],\n",
    "            'rougeL': avg_fine_tuned_scores['rougeL'] - avg_base_scores['rougeL']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_results(results: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Print evaluation results in a formatted way.\n",
    "\n",
    "    Args:\n",
    "        results: Evaluation results dictionary\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ROUGE EVALUATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nBase Model ({model_name}):\")\n",
    "    print(f\"  ROUGE-1: {results['base_model']['scores']['rouge1']:.4f}\")\n",
    "    print(f\"  ROUGE-2: {results['base_model']['scores']['rouge2']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {results['base_model']['scores']['rougeL']:.4f}\")\n",
    "    print(f\"  Avg Time: {results['base_model']['avg_time']:.3f}s\")\n",
    "\n",
    "    print(f\"\\nFine-tuned Model:\")\n",
    "    print(f\"  ROUGE-1: {results['fine_tuned_model']['scores']['rouge1']:.4f}\")\n",
    "    print(f\"  ROUGE-2: {results['fine_tuned_model']['scores']['rouge2']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {results['fine_tuned_model']['scores']['rougeL']:.4f}\")\n",
    "    print(f\"  Avg Time: {results['fine_tuned_model']['avg_time']:.3f}s\")\n",
    "\n",
    "    print(f\"\\nImprovement:\")\n",
    "    print(f\"  ROUGE-1: {results['improvement']['rouge1']:+.4f}\")\n",
    "    print(f\"  ROUGE-2: {results['improvement']['rouge2']:+.4f}\")\n",
    "    print(f\"  ROUGE-L: {results['improvement']['rougeL']:+.4f}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Evaluate on testing dataset\n",
    "dataset_path = 'data/testing_dataset.json'\n",
    "\n",
    "results = evaluate_models(dataset_path)\n",
    "\n",
    "print_results(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/testing_dataset.json...\n",
      "Evaluating on 5 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:54<00:00, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ROUGE EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Base Model (Qwen/Qwen3-0.6B):\n",
      "  ROUGE-1: 0.4733\n",
      "  ROUGE-2: 0.0414\n",
      "  ROUGE-L: 0.3733\n",
      "  Avg Time: 5.477s\n",
      "\n",
      "Fine-tuned Model:\n",
      "  ROUGE-1: 0.4867\n",
      "  ROUGE-2: 0.0345\n",
      "  ROUGE-L: 0.3667\n",
      "  Avg Time: 5.424s\n",
      "\n",
      "Improvement:\n",
      "  ROUGE-1: +0.0133\n",
      "  ROUGE-2: -0.0069\n",
      "  ROUGE-L: -0.0067\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Rouge score results are basically the same, there is no big difference by comparing base model and fine tuned model. However that might be expected, because Rouge is not really made for this task. Rouge takes test sets completion text and compares it word by word to the generated models output, so if the words are the same - Rouge score increases. But because this task is kind of a creative one for LLMs - the words can be very different and because of this Rouge score will be low."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4 - Analysis\n",
    "\n",
    "Comparing prompt engineering results and fine-tuned models results"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Factor                    | **Prompt Engineering / Few-Shot**                   | **Fine-Tuned Model**                                       |\n",
    "|---------------------------|-----------------------------------------------------|------------------------------------------------------------|\n",
    "| **Setup Cost**            | Low - just write prompts                            | Higher - requires dataset prep & training                  |\n",
    "| **Scalability**           | More manual work, need to think of the best prompt  | You can provide more examples for training                 |\n",
    "| **Creativity**            | Highly dependent on temperature and example quality | Learns patterns, moderate creativity without manual tuning |\n",
    "| **Relevance**             | Consistent                                          | Consistent                                                 |\n",
    "| **Diversity**             | Parameter-tuned prompting gave more diversity       | More TLD diversity by default                              |\n",
    "| **Control**               | Easy to tweak by just changing prompt               | Harder to tweak, because needs retraining                  |\n",
    "| **Inference Speed**       | \\~5.4s                                              | \\~5.4s                                                     |\n",
    "| **Metric Scores (ROUGE)** | Slightly lower ROUGE-1 - 0.4733                           | Slightly higher ROUGE-1 - 0.4867                                 |\n",
    "| **Cost**                  | Free                                                | Free                                                       |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Overall:\n",
    "\n",
    "Fine-tuning brings slight measurable improvement (ROUGE-1) and stylistic consistency (better diversity of TLDs and creative word combos), but doesn’t dramatically outperform prompting in raw metrics - this is common for creative tasks where \"correctness\" is subjective.\n",
    "\n",
    "Few-shot + parameter tuning is surprisingly strong: with a curated few-shot set and tuned temperature/top-p, I get nearly the same creativity without training overhead. However because I chose a small model if I would provide even more examples it would start to hallucinate and output irrelevant information.\n",
    "\n",
    "Fine-tuning should be used further for production environment, because by using it you would be able to generate a variety of different TLDs and hopefully more creative names."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Suggestions for the future\n",
    "\n",
    "By using gathered data from users which domain names they prefer or by parsing what kind of business chose what kind of name as their domain it would be easy to generate new datasets and fine tune model even further, this should provide even more uniqueness, creativeness and suggest relevant domain names.\n",
    "\n",
    "In the future it could also be possible to separate domain names and TLDs into separate suggestions and for example for each domain there would be a list with suggested relevant TLDs for it and Domain team could also check which suggested domain names are already taken, also instead of current 10 suggestions there could be much more suggestions for this particular challenge of suggesting taken domains, because the more domains suggested and creative ones the more of them should be available."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
